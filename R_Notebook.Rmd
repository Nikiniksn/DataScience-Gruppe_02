---
title: "R Notebook"
output: html_notebook
---
 
# Einbinden benötigter Bibliotheken
```{r}
library(readr)
library(ggplot2)
library(lubridate)
library(Metrics)
library(e1071)
library(dplyr)
library(broom)
library(fastDummies)
```

# Einlesen der CSV-Datein
```{r}
Umsatzdaten <- read_csv("umsatzdaten_gekuerzt.csv")

#Kiwo <- read_csv("kiwo.csv")

Kiwo_2 <- read_csv("kiwo_2.csv")

Feiertage <- read_csv("Feiertage.csv")

Schulferien <- read_csv("Schulferien.csv")

Wetter <- read_csv("wetter.csv")
```

# Integrierung der Wochentage in die Datei Umsatzdaten
```{r}
Umsatzdaten$Wochentag <- weekdays(Umsatzdaten$Datum)

# Umwandlung von 'wochentag" in eine Faktor-Variable mit einer vorgegeben Sortierung der Level (Kategorien)
Umsatzdaten$Wochentag <- factor(Umsatzdaten$Wochentag, levels=c("Montag", "Dienstag", "Mittwoch", "Donnerstag", "Freitag", "Samstag", "Sonntag"))
```

# Zusammenführung der Datein zu einer Tabelle
```{r}
Sammlung <- dplyr::full_join(Umsatzdaten,Wetter,by="Datum")
#Sammlung <- dplyr::full_join(Sammlung,Kiwo,by="Datum")
Sammlung <- dplyr::full_join(Sammlung,Kiwo_2,by="Datum")
Sammlung <- dplyr::full_join(Sammlung,Schulferien,by="Datum")
Sammlung <- dplyr::full_join(Sammlung,Feiertage,by="Datum")
```

## Aufteilung des Datensatzes in Trainings- und Testdaten
```{r}
# Zufallszähler setzen (um die zufällige Partitionierung bei jedem Durchlauf gleich zu halten)
set.seed(1)

# Zufällige Ziehung Indizes für die Zeilen des Datensatzes, die dem Traininsdatensatz zugeordnet werden
indices_train <- sample(seq_len(nrow(Sammlung)), size = floor(0.80 * nrow(Sammlung)))

# Definition des Trainings- und Testdatensatz durch Selektion bzw. Deselektion der entsprechenden Datenzeilen
train_dataset <- train_dataset_org <- Sammlung[indices_train, ]
test_dataset <- Sammlung[-indices_train, ]
```

# Vorhersage durch Wetterdaten#
```{r}
mod <- lm (Umsatz ~ Temperatur + Windgeschwindigkeit + as.factor(Wettercode) + as.factor (Bewoelkung),Sammlung) 
summary(mod)
#Kein signifikanter Einfluss der Windgeschwindigkeit auf Umsatz (eventuell u-förmigen Effekt prüfen)
#Signifikant positiver Zusammenhang zwischen Temperatur und Umsatz: Bei höheren Temperaturen ist der Umsatz höher# 
#Signifikant geringerer Umsatz bei Wettercode 71 -->  Bei durchgehendem leichten Schneefall weniger gekauft#
#Bewölkung Code 1 sagt Umsatz signifikant vorher: höherer Umsatz bei wolkenlosem Himmel, evtl Bildung dichotomer Variable sonnig vs. bewölkt###
```

# Vohersage durch Warengruppe#
```{r}
mod <-lm (Umsatz ~ as.factor (Warengruppe),Sammlung) 
summary (mod)
#Einzelne Warengruppen in signifikantem Zusammenhang mit Umsatz (logisch, Aufnahme nur bedingt sinnvoll)
#Warengruppe 2,3 und 5 sagen hohen Umsatz vorher, Warengruppe 4 und 6 (konditorei und Saisonbrot) korrelieren signifikant negativ mit Umsatz
```

# Vohersage durch Ferien###
```{r}
mod <- lm (Umsatz ~ Ferien, Sammlung)
summary (mod)
###Signifikant höherer Umsatz in Sommerferien###
```

# Vorhersage durch Feiertage
```{r}
mod <- lm (Umsatz ~ Feiertag, Sammlung)
summary (mod)
###kein signifikanter Einfluss der Feiertage, 
##eventuell Prüfung in Abhängigkeit von Ferien und langem Wochenende###
```

# Vorhersage durch Kieler Woche
```{r}
mod <-lm (Umsatz ~ KielerWoche_2, Sammlung)
summary (mod)
#Kieler Woche wirkt sich signifikant positiv auf Umsatz aus, starker Effekt**
```

# Vorhersage durch Wochentag
```{r}
mod <-lm (Umsatz ~ as.factor(Wochentag), Umsatzdaten)
summary(mod)
#Signifikant erhöhter Umsatz am Wochenende###

###Fazit: bedeutsame Haupteffekte###:

##positiv:

##Kieler Woche##
##Wochenende##
##Sommerferien##
##Sonniges Wetter##
#Verkauf Brot, Brötchen und Croissants##
##Hohe Temperaturen##

##negativ
##leichter Schneefall
##Verkauf von Saisonbrot und Konditoreiware (evtl. geringere Marge)
```

# Vorhersage durch Wetterdaten#
```{r}
mod <- lm (Umsatz ~ Windgeschwindigkeit + Temperatur,Sammlung) 
summary(mod)
```

# Estimating (Training) Models
# Nur zufällige Kombination von Faktoren
# To Do: Systematisierung der Faktoren und Integration von Wochentages, Feiertagen und Ferien###
```{r}
mod1 <- lm(Umsatz ~ Temperatur, Sammlung)
mod2 <- lm(Umsatz ~ Temperatur, Sammlung)
mod3 <- lm(Umsatz ~ Temperatur + as.factor(Windgeschwindigkeit) + as.factor(Bewoelkung), Sammlung)
mod4 <- lm(Umsatz ~ Temperatur + as.factor(Windgeschwindigkeit) + as.factor(Bewoelkung) + as.factor(Wettercode), Sammlung)
mod5 <- lm(Umsatz ~ Temperatur + as.factor(Windgeschwindigkeit) + as.factor(Bewoelkung) + as.factor(Wettercode) + as.factor(Warengruppe), Sammlung)
mod6 <- lm(Umsatz ~ Temperatur + as.factor(Windgeschwindigkeit) + as.factor(Bewoelkung) + as.factor(Wettercode) + as.factor(Warengruppe) + KielerWoche_2, Sammlung)
mod7 <- lm(Umsatz ~ Temperatur + as.factor(Windgeschwindigkeit) + Windgeschwindigkeit*Temperatur + as.factor(Bewoelkung) + as.factor(Wettercode) + as.factor(Warengruppe) + KielerWoche_2 , Sammlung)
```

```{r}
summary(mod1)
summary (mod2)
summary(mod3)
summary(mod3)
summary(mod4)
summary(mod5)
summary(mod6)
summary(mod7)
```

```{r}
glance(mod1)
glance (mod2)
glance (mod3)
glance (mod4)
glance (mod5)
glance (mod6)
glance (mod7)
```

# Preparation of Model Results
```{r}
rbind(glance(mod1), glance(mod2), glance(mod3), glance(mod4), glance(mod5), glance(mod6), glance(mod7))
```

#Vorhersageverbesserung vor allem durch Aufnahme von Warengruppe und Kieler Woche,
#Aufnahme von Warengruppe jedoch nur bedingt sinnvoll#
#Kieler Woche als sehr starker Umsatztreiber###
##To Do: Unbedingt Wochentag und Ferien intergieren, da sign. Korrelation mit Umsatz in einfacher Regression#
```{r}
# Model Prediction Quality for the Training Data Using the Mean Absolute Error
rbind(mae(Sammlung$Umsatz, predict(mod1)),
      mae(Sammlung$Umsatz, predict(mod2)),
      mae(Sammlung$Umsatz, predict(mod3)),
      mae(Sammlung$Umsatz, predict(mod4)),
      mae(Sammlung$Umsatz, predict(mod5)),
      mae(Sammlung$Umsatz, predict(mod6)),
      mae(Sammlung$Umsatz, predict(mod7)))
```

```{r}
# Model Prediction Quality for the Training Data Using the Mean Absolute Percentage Error
rbind(mape(Sammlung$Umsatz, predict(mod1)),
       mape(Sammlung$Umsatz, predict(mod2)),
       mape(Sammlung$Umsatz, predict(mod3)),
       mape(Sammlung$Umsatz, predict(mod4)),
       mape(Sammlung$Umsatz, predict(mod5)),
       mape(Sammlung$Umsatz, predict(mod6)),
       mape(Sammlung$Umsatz, predict(mod7)))
```

```{r}
# Model Prediction Quality for the (Unknown) Test Data Using the Mean Absolute Percentage Error
rbind(mape(Sammlung$Umsatz, predict(mod1, newdata=test_dataset)),
      mape(Sammlung$Umsatz, predict(mod2, newdata=test_dataset)),
      mape(Sammlung$Umsatz, predict(mod3, newdata=test_dataset)),
      mape(Sammlung$Umsatz, predict(mod4, newdata=test_dataset)),
      mape(Sammlung$Umsatz, predict(mod5, newdata=test_dataset)),
      mape(Sammlung$Umsatz, predict(mod6, newdata=test_dataset)))
```

## Data Preparation
```{r}
# Uncomment the following line to check the correctness of the code with a small (and computationally fast) training data set
train_dataset <- sample_frac(train_dataset_org, .10)
```

## Training the SVM
```{r}
# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(Umsatz ~ Wochentag, train_dataset)
```

```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, Umsatz ~ Wochentag + Bewoelkung + Temperatur + Ferien, data=train_dataset,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))
```

## Checking the Prediction Quality
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$price, pred_train)
```

```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(test_dataset$Umsatz, pred_test)
```

# Datenaufbereitung
```{r}
# Rekodierung von kategoriellen Variablen (zu Dummy-Variablen)
dummy_list <- c("view", "Warengruppe")
Sammlung_dummy = dummy_cols(Sammlung, dummy_list)

# Definition von Variablenlisten für die Dummies, um das Arbeiten mit diesen zu erleichtern
Warengruppe_dummies = c('warengruppe_1', 'warengruppe_2', 'condition_3', 'condition_4', 'condition_5')
view_dummies = c('view_0', 'view_1', 'view_2', 'view_3','view_4')


# Standardisierung aller Feature Variablen und der Label Variable
norm_list <- c("Umsatz", "Temperatur", "Bewoelkung", "Windgeschwindigkeit", view_dummies, Warengruppe_dummies) # Liste aller Variablen
norm_values_list <- get.norm_values(Sammlung_dummy, norm_list)    # Berechnung der Mittelwerte und Std.-Abw. der Variablen
Sammlung_norm <- norm_cols(Sammlung_dummy, norm_values_list) # Standardisierung der Variablen
```

# Definition der Feaure-Variablen und der Label-Variable
```{r}
# Definition der Features (der unabhängigen Variablen auf deren Basis die Vorhersagen erzeugt werden sollen)
features = c('sqft_lot', 'waterfront', 'grade', 'bathrooms', view_dummies, condition_dummies)
# Definition der Label-Variable (der abhaengigen Variable, die vorhergesagt werden soll) sowie
label = 'price_norm'
```

# Definition von Trainings- und Testdatensatz
```{r}
# Zufallszähler setzen, um die zufällige Partitionierung bei jedem Durchlauf gleich zu halten
set.seed(1)
# Bestimmung der Indizes des Traininsdatensatzes
train_ind <- sample(seq_len(nrow(house_pricing_norm)), size = floor(0.80 * nrow(house_pricing_norm)))

# Teilen in Trainings- und Testdatensatz
train_dataset = house_pricing_norm[train_ind, features]
test_dataset = house_pricing_norm[-train_ind, features]

# Selektion der Variable, die als Label definiert wurde
train_labels = house_pricing_norm[train_ind, label]
test_labels = house_pricing_norm[-train_ind, label]
```

### Installation von Python und TensorFlow (nur einmalig nötig)

```{r}
#  install.packages("reticulate")
#  library(reticulate)
#  
#  # Installation von miniconda (falls nicht vorhanden)
#  install_miniconda()
#  
#  # Anlegen einer speziellen Python Umgebung
#  conda_create("r-reticulate")
#  
#  # Installieren der Pakete in der angelegten Umgebung
#  conda_install("r-reticulate", "pandas")
#  conda_install("r-reticulate", "numpy")
#  conda_install("r-reticulate", "tensorflow")
#  
# # Verwenden der speziellen Python Umgebung die zuvor erstellt wurde
# use_condaenv("r-reticulate")

```


### Aufruf des Skripts zur Datenaufbereitung
```{r}
source("neural-net-data-preparation.R")

```


### Laden benötigter  Packages
```{r}
library(reticulate)
library(ggplot2)
library(Metrics)

```


### Definition des Neuronalen Netzes
```{python}
# Benoetigte Python Libraries einbinden
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Definition der Form des tiefen neuronalen Netzes (Deep Neural Nets)
model = keras.Sequential([
  layers.Dense(10, activation='relu', input_shape=[len(r.train_dataset.keys())]),
  layers.Dense(4, activation='relu'),
  layers.Dense(1)
])

# Definition der Kosten-(Loss-)Funktion und der Optimierungsfunktion mit seinen Hyperparametern
model.compile(loss="mse",
              optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))

# Ausgabe einer Zusammenfassung zur Form des Modells, das geschaetzt wird (nicht notwendig)
model.summary()


```

### Schätzung des neuronalen Netzes

```{python}
# Schaetzung des Modells
history = model.fit(r.train_dataset, r.train_labels, epochs=150, validation_data = (r.test_dataset, r.test_labels), verbose=0)

# Ggf. Speichern des geschaetzten Modells
# model.save("python_model.h5")

```



### Auswertung der Modelloptimierung
```{r}
# Grafische Ausgabe der Modelloptimierung

# create data
data <- data.frame(val_loss = unlist(py$history$history$val_loss),
                  loss = unlist(py$history$history$loss))

# Plot
ggplot(data[-1,]) +
  geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
  geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
  scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
  labs(title="Loss Function Values During Optimization") +
  xlab("Iteration Number") +
  ylab("Loss") 


```


### (Ggf.) Laden eines gespeicherten Neuronalen Netzes ###
```{python}
model = keras.models.load_model("python_model_best.h5")

```


### Auswertung der Schätzergebnisse ###
```{r}
# Schätzung der (normierten) Preise für die Trainings- und Testdaten
train_predictions_norm <- py$model$predict(train_dataset)
test_predictions_norm <- py$model$predict(test_dataset)

# Rückberechnung der normierten Preisschätzungen zu den tatsächlichen Preisschätzungen bzw. Preisen
train_predictions <- (train_predictions_norm * norm_values_list$sd[1] ) + norm_values_list$mean[1]
test_predictions <- (test_predictions_norm * norm_values_list$sd[1]) + norm_values_list$mean[1]
# Selektion der zugehörigen tatsächlichen Preise
train_actuals <- house_pricing$price[train_ind]
test_actuals <- house_pricing$price[-train_ind]


# Vergleich der Gütekriterien für die Traingings- und Testdaten
cat(paste0("MAPE on the Training Data:\t", format(mape(train_actuals, train_predictions)*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Test Data:\t\t", format(mape(test_actuals, test_predictions)*100, digits=3, nsmall=2)))


```

```{r}

## Grafischer vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten

# Zusammenstellung der Daten für die Plots
data_train <- data.frame(prediction = train_predictions/1000, actual = train_actuals/1000)
data_test <- data.frame(prediction = test_predictions/1000, actual = test_actuals/1000)

# Plot der Ergebnisse der Trainingsdaten
ggplot(data_train[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Training Data") +
  xlab("Case Number") +
  ylab("Price in 1.000 USD") 

# Plot der Ergebnisse der Testdaten
ggplot(data_test[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Test Data") +
  xlab("Case Number") +
  ylab("Price in 1.000 USD") 


```

# Vorhersage für einen einzelnen Fall
```{r}
cat(paste0("Vorergesagter Preis:\t", format(test_predictions[100], digits=2, nsmall =0)))
cat(paste0("\nTatsächlicher Preis:\t", test_actuals[100]))

#Folgende Daten müssen vorhergesagt werden
# SVM 04.06.2019 je Warengruppe und Warengruppenumsatz
# Neuronales Netz 04.06.2019 je Warengruppe und Warengruppenumsatz
```







